{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  12%|█▎        | 1/8 [00:11<01:17, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Cell_Phones_and_Accessories.json\n",
      "Extracted samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  25%|██▌       | 2/8 [01:04<03:34, 35.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Clothing_Shoes_and_Jewelry.json\n",
      "Extracted samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  38%|███▊      | 3/8 [01:39<02:56, 35.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Electronics.json\n",
      "Extracted samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 4/8 [01:53<01:47, 26.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Home_and_Kitchen.json\n",
      "Extracted samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  62%|██████▎   | 5/8 [01:54<00:52, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: part.json\n",
      "Extracted samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  75%|███████▌  | 6/8 [01:57<00:25, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: separate.json\n",
      "Extracted samples: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 7/8 [02:00<00:09,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Sports_and_Outdoors.json\n",
      "Extracted samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8/8 [02:03<00:00, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: Toys_and_Games.json\n",
      "Extracted samples: 50\n",
      "\n",
      "Final combined dataset:\n",
      "Total samples: 350\n",
      "Saved to: C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\validation_dataset.json\n",
      "\n",
      "Class distribution in combined dataset:\n",
      "Class 0: 111 samples (31.71%)\n",
      "Class 1: 239 samples (68.29%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification:\n",
      "Total examples in combined dataset: 350\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 或者使用 Path 对象创建路径\n",
    "base_dir = Path(r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\")\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Cell_Phones_and_Accessories.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Clothing_Shoes_and_Jewelry.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Electronics.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Home_and_Kitchen.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\part.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\separate.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Sports_and_Outdoors.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Toys_and_Games.json\"\n",
    "]\n",
    "\n",
    "def extract_and_combine_datasets(file_paths, samples_per_file, output_file):\n",
    "    \"\"\"\n",
    "    从多个JSON文件中提取样本并组合\n",
    "    \"\"\"\n",
    "    combined_data = []\n",
    "    \n",
    "    # 处理每个文件\n",
    "    for file_path in tqdm(file_paths, desc=\"Processing files\"):\n",
    "        samples = []\n",
    "        try:\n",
    "            # 使用 Path 对象处理路径\n",
    "            file_path = Path(file_path)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "                if len(lines) <= samples_per_file:\n",
    "                    selected_lines = lines\n",
    "                else:\n",
    "                    selected_lines = random.sample(lines, samples_per_file)\n",
    "                \n",
    "                for line in selected_lines:\n",
    "                    try:\n",
    "                        sample = json.loads(line.strip())\n",
    "                        samples.append(sample)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                \n",
    "                print(f\"\\nFile: {file_path.name}\")\n",
    "                print(f\"Extracted samples: {len(samples)}\")\n",
    "                combined_data.extend(samples)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 随机打乱并保存\n",
    "    random.shuffle(combined_data)\n",
    "    \n",
    "    # 使用 Path 对象处理输出路径\n",
    "    output_path = Path(output_file)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for item in combined_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    \n",
    "    print(f\"\\nFinal combined dataset:\")\n",
    "    print(f\"Total samples: {len(combined_data)}\")\n",
    "    print(f\"Saved to: {output_path}\")\n",
    "    \n",
    "    # 显示类别分布\n",
    "    class_distribution = {}\n",
    "    for item in combined_data:\n",
    "        class_label = str(int(item.get('class', 0)))\n",
    "        class_distribution[class_label] = class_distribution.get(class_label, 0) + 1\n",
    "    \n",
    "    print(\"\\nClass distribution in combined dataset:\")\n",
    "    for class_label, count in class_distribution.items():\n",
    "        print(f\"Class {class_label}: {count} samples ({count/len(combined_data)*100:.2f}%)\")\n",
    "\n",
    "# 执行组合\n",
    "# 使用 Path 对象创建输出路径\n",
    "output_dir = base_dir\n",
    "output_dir.mkdir(exist_ok=True)  # 创建输出目录（如果不存在）\n",
    "output_file = output_dir / \"validation_dataset.json\"\n",
    "\n",
    "extract_and_combine_datasets(\n",
    "    file_paths=file_paths,\n",
    "    samples_per_file=50,\n",
    "    output_file=str(output_file)\n",
    ")\n",
    "\n",
    "# 验证\n",
    "with open(output_file, 'r', encoding='utf-8') as f:\n",
    "    combined_examples = [json.loads(line) for line in f]\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Total examples in combined dataset: {len(combined_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Combined Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading JSON file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 7000it [00:00, 109196.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Statistics:\n",
      "Total JSON records: 7000\n",
      "Unique reviews: 6999\n",
      "\n",
      "DataFrame Info:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   _id                       7000 non-null   object \n",
      " 1   reviewerID                7000 non-null   object \n",
      " 2   asin                      7000 non-null   object \n",
      " 3   reviewerName              6959 non-null   object \n",
      " 4   helpful                   7000 non-null   object \n",
      " 5   reviewText                7000 non-null   object \n",
      " 6   overall                   7000 non-null   float64\n",
      " 7   summary                   7000 non-null   object \n",
      " 8   unixReviewTime            7000 non-null   int64  \n",
      " 9   reviewTime                7000 non-null   object \n",
      " 10  category                  7000 non-null   object \n",
      " 11  class                     6000 non-null   float64\n",
      " 12  BehaviouralFeatureResult  1000 non-null   object \n",
      " 13  label                     205 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(10)\n",
      "memory usage: 765.8+ KB\n",
      "None\n",
      "\n",
      "Sample records:\n",
      "                                    _id      reviewerID        asin  \\\n",
      "0  {'$oid': '5a13258b741a2384e8f64fd6'}  A1F60NFSJ0LR0Z  B009VV56TY   \n",
      "1  {'$oid': '5a132225741a2384e81ddb0b'}  A1VEXDIWF163XV  B008D4X97Q   \n",
      "2  {'$oid': '5a132495741a2384e8ad447f'}  A1IYPGC7B1NACR  B001ELJER4   \n",
      "3  {'$oid': '5a13253c741a2384e8de39d9'}   AUA8JYGKH6TO2  B005S72HHO   \n",
      "4  {'$oid': '5a1325ec741a2384e814ff79'}  A2GUT03DCT7A11  B000FOTZGQ   \n",
      "\n",
      "      reviewerName helpful                                         reviewText  \\\n",
      "0          B. Shea  [0, 0]  I upgraded to the H80i from a Cooler Master Hy...   \n",
      "1            candi  [0, 1]  I put this on my phone and my phone fell off t...   \n",
      "2             JayR  [0, 3]  Garmin has slipped up big-time.  I guess they'...   \n",
      "3       D. Vernier  [0, 0]  I may buy another of these FTDI chip USB to se...   \n",
      "4  Gaurav Kulkarni  [8, 8]  Simple design. Keeps tea hot for at least 4 - ...   \n",
      "\n",
      "   overall                                summary  unixReviewTime  \\\n",
      "0      4.0  Works well, but noisier than expected      1397347200   \n",
      "1      1.0            Does not Protect your phone      1384905600   \n",
      "2      2.0                           This is crap      1268438400   \n",
      "3      5.0                Good buy for arouns $10      1395705600   \n",
      "4      5.0                               Good buy      1246838400   \n",
      "\n",
      "    reviewTime                     category  class BehaviouralFeatureResult  \\\n",
      "0  04 13, 2014                  Electronics    1.0                      NaN   \n",
      "1  11 20, 2013  Cell_Phones_and_Accessories    0.0                      NaN   \n",
      "2  03 13, 2010                  Electronics    0.0                      NaN   \n",
      "3  03 25, 2014                  Electronics    1.0                      NaN   \n",
      "4   07 6, 2009             Home_and_Kitchen    1.0                      NaN   \n",
      "\n",
      "   label  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2    NaN  \n",
      "3    NaN  \n",
      "4    NaN  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 文件路径\n",
    "json_path = r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\combined_dataset.json\"\n",
    "\n",
    "# 读取整个JSON文件\n",
    "print(\"Reading JSON file...\")\n",
    "all_records = []\n",
    "unique_texts = set()  # 用于检查重复\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f, desc=\"Processing records\"):\n",
    "        try:\n",
    "            review = json.loads(line.strip())\n",
    "            # 存储原始记录\n",
    "            all_records.append(review)\n",
    "            # 存储review text用于检查重复\n",
    "            unique_texts.add(review.get('reviewText', ''))\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Found invalid JSON line\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# 打印基本统计信息\n",
    "print(\"\\nData Statistics:\")\n",
    "print(f\"Total JSON records: {len(all_records)}\")\n",
    "print(f\"Unique reviews: {len(unique_texts)}\")\n",
    "\n",
    "# 转换为DataFrame以便更详细的分析\n",
    "df = pd.DataFrame(all_records)\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# 显示几个样本\n",
    "print(\"\\nSample records:\")\n",
    "print(df.head())\n",
    "\n",
    "# 保存处理后的数据\n",
    "df.to_csv(r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Invalid Data in Original Datasets & Convert Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Joyce\\\\OneDrive\\\\桌面\\\\24 Fall\\\\CS6220\\\\Project\\\\FilteredData'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# List of JSON file paths\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Cell_Phones_and_Accessories.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Clothing_Shoes_and_Jewelry.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Electronics.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Home_and_Kitchen.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\part.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\separate.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Sports_and_Outdoors.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\Toys_and_Games.json\"\n",
    "]\n",
    "\n",
    "# Output directory for filtered datasets\n",
    "output_directory = r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for file_path in tqdm(file_paths, desc=\"Processing files\"):\n",
    "    data = []\n",
    "    # Load JSON data line by line\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Processing files\"):\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                data.append(item)\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # Skip invalid JSON lines\n",
    "\n",
    "    # Filter and transform data\n",
    "    training_data = []\n",
    "    for example in data:\n",
    "        try:\n",
    "            if isinstance(example, dict) and 'reviewText' in example and 'class' in example:\n",
    "                if isinstance(example['reviewText'], str) and isinstance(example['class'], (int, float)):\n",
    "                    training_data.append({\n",
    "                        'text_input': example['reviewText'],\n",
    "                        'output': str(int(example['class']))  # Convert to string format\n",
    "                    })\n",
    "        except:\n",
    "            continue  # Skip any example that causes an error\n",
    "\n",
    "    # Save the filtered dataset\n",
    "    output_file_name = os.path.basename(file_path).replace('.json', '_filtered.json')\n",
    "    output_path = os.path.join(output_directory, output_file_name)\n",
    "    with open(output_path, 'w', encoding='utf-8') as out_file:\n",
    "        json.dump(training_data, out_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "output_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Filtered Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Joyce\\\\OneDrive\\\\桌面\\\\24 Fall\\\\CS6220\\\\Project\\\\Data\\\\combined_dataset.json',\n",
       " 'C:\\\\Users\\\\Joyce\\\\OneDrive\\\\桌面\\\\24 Fall\\\\CS6220\\\\Project\\\\Data\\\\combined_dataset_csv.csv')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Cell_Phones_and_Accessories_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Clothing_Shoes_and_Jewelry_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Electronics_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Home_and_Kitchen_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\part_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\separate_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Sports_and_Outdoors_filtered.json\",\n",
    "    r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Toys_and_Games_filtered.json\"\n",
    "]  \n",
    "\n",
    "combined_data = []\n",
    "sample_size = 1000\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            valid_samples = []\n",
    "            for sample in data[:sample_size]:\n",
    "                try:\n",
    "                    valid_samples.append(sample)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping a problematic sample in file {file_path}.\")\n",
    "            combined_data.extend(valid_samples)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Entire file {file_path} could not be read, skipping this file.\")\n",
    "\n",
    "\n",
    "# Saving as JSON\n",
    "combined_json_path = r'C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\combined_dataset.json'\n",
    "with open(combined_json_path, 'w') as f:\n",
    "    json.dump(combined_data, f, indent=2)\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "combined_csv_path = r'C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\Data\\combined_dataset_csv.csv'\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "combined_json_path, combined_csv_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Joyce\\OneDrive\\桌面\\24 Fall\\CS6220\\Project\\FilteredData\\Cell_Phones_and_Accessories_filtered.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
