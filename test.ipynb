{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T20:14:36.885593Z",
     "start_time": "2024-11-16T20:14:30.498468Z"
    }
   },
   "source": [
    "# !python reassembler_BERT.py\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "import torch.nn.functional as F\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# BERT model definition\n",
    "class BertLSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels=2, hidden_size=768, lstm_hidden_size=256, num_lstm_layers=1):\n",
    "        super(BertLSTMClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.lstm = torch.nn.LSTM(input_size=hidden_size,hidden_size=lstm_hidden_size,num_layers=num_lstm_layers,batch_first=True,bidirectional=False)\n",
    "        self.classifier = torch.nn.Linear(lstm_hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state \n",
    "        lstm_output, _ = self.lstm(sequence_output) \n",
    "        lstm_output = lstm_output[:, -1, :] \n",
    "        logits = self.classifier(lstm_output) \n",
    "        return logits\n",
    "\n",
    "model_dir = './'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = BertLSTMClassifier(model_name='bert-base-uncased', num_labels=2)\n",
    "\n",
    "\n",
    "model_state_dict = load_file(f'{model_dir}BERTLSTM.safetensors')\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# prediction\n",
    "def predict(text):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    return predicted_class, probabilities.cpu().numpy()\n",
    "\n",
    "# Example \n",
    "text = \"The product did not meet my expectations.\"\n",
    "predicted_class, probabilities = predict(text)\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Probabilities: {probabilities}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mps_speed/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n",
      "Probabilities: [[0.99386686 0.00613318]]\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
